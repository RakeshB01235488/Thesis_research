{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats\n",
    "from scipy import stats, optimize\n",
    "from scipy.stats import genextreme\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sn.set(rc={'figure.figsize':(21, 9)})\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('data-1.csv')\n",
    "data = pd.read_csv('combine_partial_lag_0.csv')\n",
    "#data = pd.read_csv('combine_partial_NoLag-1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>East_12</th>\n",
       "      <th>lag_east_12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>49.2</th>\n",
       "      <th>50.2</th>\n",
       "      <th>51.2</th>\n",
       "      <th>52.2</th>\n",
       "      <th>53.2</th>\n",
       "      <th>54.2</th>\n",
       "      <th>55.2</th>\n",
       "      <th>56.2</th>\n",
       "      <th>57.2</th>\n",
       "      <th>58.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.017703</td>\n",
       "      <td>-0.016553</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>0.082478</td>\n",
       "      <td>0.130230</td>\n",
       "      <td>0.139420</td>\n",
       "      <td>0.141490</td>\n",
       "      <td>0.12413</td>\n",
       "      <td>0.14460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>-0.001766</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.004655</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.003451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>-0.028014</td>\n",
       "      <td>0.027178</td>\n",
       "      <td>0.053463</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.120980</td>\n",
       "      <td>0.137650</td>\n",
       "      <td>0.148710</td>\n",
       "      <td>0.13235</td>\n",
       "      <td>0.13501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>-0.002080</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.004295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.026863</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.039995</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.115810</td>\n",
       "      <td>0.121480</td>\n",
       "      <td>0.137530</td>\n",
       "      <td>0.156670</td>\n",
       "      <td>0.14227</td>\n",
       "      <td>0.13988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>-0.003118</td>\n",
       "      <td>-0.006825</td>\n",
       "      <td>-0.001222</td>\n",
       "      <td>-0.003579</td>\n",
       "      <td>-0.002215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>0.039388</td>\n",
       "      <td>0.027085</td>\n",
       "      <td>0.082073</td>\n",
       "      <td>0.115360</td>\n",
       "      <td>0.133080</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.178490</td>\n",
       "      <td>0.17368</td>\n",
       "      <td>0.18923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.001392</td>\n",
       "      <td>-0.001417</td>\n",
       "      <td>-0.005652</td>\n",
       "      <td>-0.007379</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>-0.003790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.023506</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>-0.003510</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>0.056934</td>\n",
       "      <td>0.098202</td>\n",
       "      <td>0.130510</td>\n",
       "      <td>0.160280</td>\n",
       "      <td>0.18006</td>\n",
       "      <td>0.21011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.001703</td>\n",
       "      <td>-0.001424</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>-0.006904</td>\n",
       "      <td>-0.006104</td>\n",
       "      <td>-0.001440</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>-0.004034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1595</td>\n",
       "      <td>-0.037374</td>\n",
       "      <td>0.021999</td>\n",
       "      <td>-0.046919</td>\n",
       "      <td>-0.026823</td>\n",
       "      <td>0.021059</td>\n",
       "      <td>0.050554</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.133590</td>\n",
       "      <td>0.18231</td>\n",
       "      <td>0.23533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.001479</td>\n",
       "      <td>0.004387</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1596</td>\n",
       "      <td>-0.059373</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>-0.065855</td>\n",
       "      <td>-0.060359</td>\n",
       "      <td>-0.003867</td>\n",
       "      <td>0.030398</td>\n",
       "      <td>0.079186</td>\n",
       "      <td>0.097516</td>\n",
       "      <td>0.16213</td>\n",
       "      <td>0.21842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>-0.001691</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.002468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1597</td>\n",
       "      <td>-0.073638</td>\n",
       "      <td>-0.046953</td>\n",
       "      <td>-0.066995</td>\n",
       "      <td>-0.058604</td>\n",
       "      <td>-0.013420</td>\n",
       "      <td>0.017367</td>\n",
       "      <td>0.059109</td>\n",
       "      <td>0.078131</td>\n",
       "      <td>0.13627</td>\n",
       "      <td>0.18862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.002860</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>-0.002021</td>\n",
       "      <td>-0.003631</td>\n",
       "      <td>-0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1598</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>-0.020820</td>\n",
       "      <td>-0.006613</td>\n",
       "      <td>0.019691</td>\n",
       "      <td>0.058844</td>\n",
       "      <td>0.072697</td>\n",
       "      <td>0.120290</td>\n",
       "      <td>0.140470</td>\n",
       "      <td>0.17203</td>\n",
       "      <td>0.21967</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000649</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>-0.000674</td>\n",
       "      <td>-0.002238</td>\n",
       "      <td>0.000660</td>\n",
       "      <td>-0.002738</td>\n",
       "      <td>-0.007083</td>\n",
       "      <td>-0.006382</td>\n",
       "      <td>-0.004409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1599</td>\n",
       "      <td>-0.005865</td>\n",
       "      <td>0.017512</td>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.042347</td>\n",
       "      <td>0.074073</td>\n",
       "      <td>0.094853</td>\n",
       "      <td>0.143320</td>\n",
       "      <td>0.176290</td>\n",
       "      <td>0.21213</td>\n",
       "      <td>0.25211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000954</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>-0.001599</td>\n",
       "      <td>-0.000771</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.004511</td>\n",
       "      <td>-0.003115</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       East_12  lag_east_12        13        14        15        16        17  \\\n",
       "0    -0.017703    -0.016553  0.021267  0.042634  0.082478  0.130230  0.139420   \n",
       "1    -0.001151    -0.028014  0.027178  0.053463  0.090675  0.120980  0.137650   \n",
       "2     0.026863     0.010981  0.039995  0.089400  0.115810  0.121480  0.137530   \n",
       "3     0.015882     0.039388  0.027085  0.082073  0.115360  0.133080  0.152590   \n",
       "4    -0.023506     0.011090 -0.003510  0.034058  0.056934  0.098202  0.130510   \n",
       "...        ...          ...       ...       ...       ...       ...       ...   \n",
       "1595 -0.037374     0.021999 -0.046919 -0.026823  0.021059  0.050554  0.109600   \n",
       "1596 -0.059373     0.014265 -0.065855 -0.060359 -0.003867  0.030398  0.079186   \n",
       "1597 -0.073638    -0.046953 -0.066995 -0.058604 -0.013420  0.017367  0.059109   \n",
       "1598 -0.026685    -0.020820 -0.006613  0.019691  0.058844  0.072697  0.120290   \n",
       "1599 -0.005865     0.017512  0.021329  0.042347  0.074073  0.094853  0.143320   \n",
       "\n",
       "            18       19       20  ...      49.2      50.2      51.2      52.2  \\\n",
       "0     0.141490  0.12413  0.14460  ...  0.002730  0.001201 -0.001766  0.005172   \n",
       "1     0.148710  0.13235  0.13501  ...  0.002280 -0.000927 -0.002955  0.004738   \n",
       "2     0.156670  0.14227  0.13988  ...  0.001380  0.000830 -0.001670  0.001650   \n",
       "3     0.178490  0.17368  0.18923  ... -0.000976  0.001851 -0.000283 -0.001392   \n",
       "4     0.160280  0.18006  0.21011  ... -0.000047  0.000326 -0.001703 -0.001424   \n",
       "...        ...      ...      ...  ...       ...       ...       ...       ...   \n",
       "1595  0.133590  0.18231  0.23533  ...  0.002944  0.003265  0.005050  0.002603   \n",
       "1596  0.097516  0.16213  0.21842  ...  0.001534  0.002233  0.004449 -0.001691   \n",
       "1597  0.078131  0.13627  0.18862  ...  0.002072  0.000454  0.002860  0.000392   \n",
       "1598  0.140470  0.17203  0.21967  ... -0.000649  0.000430  0.001610 -0.000674   \n",
       "1599  0.176290  0.21213  0.25211  ... -0.000954  0.001527  0.001339 -0.001599   \n",
       "\n",
       "          53.2      54.2      55.2      56.2      57.2      58.2  \n",
       "0     0.004519  0.006129  0.004212  0.004655  0.001408  0.003451  \n",
       "1     0.002229  0.001678 -0.002080  0.002313 -0.000923  0.004295  \n",
       "2    -0.000317 -0.003118 -0.006825 -0.001222 -0.003579 -0.002215  \n",
       "3    -0.001417 -0.005652 -0.007379 -0.001470 -0.001904 -0.003790  \n",
       "4    -0.002720 -0.006904 -0.006104 -0.001440 -0.001904 -0.004034  \n",
       "...        ...       ...       ...       ...       ...       ...  \n",
       "1595  0.001479  0.004387  0.001433  0.001364  0.001453  0.003321  \n",
       "1596  0.000040  0.001875 -0.000201  0.000972  0.001081  0.002468  \n",
       "1597 -0.000318  0.001540  0.000687 -0.002021 -0.003631 -0.002200  \n",
       "1598 -0.002238  0.000660 -0.002738 -0.007083 -0.006382 -0.004409  \n",
       "1599 -0.000771 -0.001402 -0.004919 -0.004511 -0.003115  0.000094  \n",
       "\n",
       "[1600 rows x 140 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = data.values\n",
    "features = data_values[:,1:]\n",
    "values = data_values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.65525e-02,  2.12670e-02,  4.26340e-02, ...,  4.65540e-03,\n",
       "         1.40840e-03,  3.45120e-03],\n",
       "       [-2.80135e-02,  2.71780e-02,  5.34630e-02, ...,  2.31340e-03,\n",
       "        -9.23040e-04,  4.29470e-03],\n",
       "       [ 1.09810e-02,  3.99950e-02,  8.94000e-02, ..., -1.22200e-03,\n",
       "        -3.57900e-03, -2.21460e-03],\n",
       "       ...,\n",
       "       [-4.69530e-02, -6.69950e-02, -5.86040e-02, ..., -2.02140e-03,\n",
       "        -3.63100e-03, -2.20050e-03],\n",
       "       [-2.08203e-02, -6.61340e-03,  1.96910e-02, ..., -7.08350e-03,\n",
       "        -6.38210e-03, -4.40870e-03],\n",
       "       [ 1.75123e-02,  2.13290e-02,  4.23470e-02, ..., -4.51130e-03,\n",
       "        -3.11520e-03,  9.35000e-05]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "clf = GradientBoostingRegressor(loss='ls', learning_rate=0.1, n_estimators=100,\n",
    "       subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1,\n",
    "       min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "       init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, \n",
    "       warm_start=False, presort='auto', validation_fraction=0.1, tol=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "clf2 = RandomForestRegressor(n_estimators=100, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import r2_score\n",
    "# arr_r2 = []\n",
    "\n",
    "# for i in range(10):\n",
    "    \n",
    "#     X_train, X_test, Y_train, Y_test = train_test_split(features, values,test_size=0.3)\n",
    "#     clf.fit(X_train, Y_train, sample_weight=None)\n",
    "#     predict_Y = clf.predict(X_test)\n",
    "#     arr_r2.append(r2_score(Y_test, predict_Y))\n",
    "    \n",
    "\n",
    "# arr_r2\n",
    "# np.mean(arr_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "                          learning_rate=0.1, loss='ls', max_depth=3,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                          n_iter_no_change=None, presort='auto',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(features, values, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=None,\n",
       "                      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf2.fit(features, values, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = pd.read_csv('data-2.csv')\n",
    "test_data = pd.read_csv('combine_partial_lag_1.csv')\n",
    "#test_data = pd.read_csv('combine_partial_NoLag-2.csv')\n",
    "#test_data = test_data.head(500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_values = test_data.values\n",
    "test_features = test_data_values[:,1:]\n",
    "test_values = test_data_values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = clf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred2 = clf2.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9850742665988801"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(test_values, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9864864183495504"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import r2_score\n",
    "# r2_score(test_values, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
