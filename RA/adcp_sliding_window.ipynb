{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats\n",
    "from scipy import stats, optimize\n",
    "from scipy.stats import genextreme\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sn.set(rc={'figure.figsize':(21, 9)})\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('combine_partial_lag.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>East_12</th>\n",
       "      <th>lag_east_12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>49.2</th>\n",
       "      <th>50.2</th>\n",
       "      <th>51.2</th>\n",
       "      <th>52.2</th>\n",
       "      <th>53.2</th>\n",
       "      <th>54.2</th>\n",
       "      <th>55.2</th>\n",
       "      <th>56.2</th>\n",
       "      <th>57.2</th>\n",
       "      <th>58.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-0.017703</td>\n",
       "      <td>-0.016553</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>0.082478</td>\n",
       "      <td>0.130230</td>\n",
       "      <td>0.139420</td>\n",
       "      <td>0.141490</td>\n",
       "      <td>0.124130</td>\n",
       "      <td>0.14460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>-0.001766</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.004519</td>\n",
       "      <td>0.006129</td>\n",
       "      <td>0.004212</td>\n",
       "      <td>0.004655</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.003451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>-0.028014</td>\n",
       "      <td>0.027178</td>\n",
       "      <td>0.053463</td>\n",
       "      <td>0.090675</td>\n",
       "      <td>0.120980</td>\n",
       "      <td>0.137650</td>\n",
       "      <td>0.148710</td>\n",
       "      <td>0.132350</td>\n",
       "      <td>0.13501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>0.004738</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>-0.002080</td>\n",
       "      <td>0.002313</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>0.004295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.026863</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.039995</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.115810</td>\n",
       "      <td>0.121480</td>\n",
       "      <td>0.137530</td>\n",
       "      <td>0.156670</td>\n",
       "      <td>0.142270</td>\n",
       "      <td>0.13988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>-0.000317</td>\n",
       "      <td>-0.003118</td>\n",
       "      <td>-0.006825</td>\n",
       "      <td>-0.001222</td>\n",
       "      <td>-0.003579</td>\n",
       "      <td>-0.002215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>0.039388</td>\n",
       "      <td>0.027085</td>\n",
       "      <td>0.082073</td>\n",
       "      <td>0.115360</td>\n",
       "      <td>0.133080</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.178490</td>\n",
       "      <td>0.173680</td>\n",
       "      <td>0.18923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000976</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>-0.000283</td>\n",
       "      <td>-0.001392</td>\n",
       "      <td>-0.001417</td>\n",
       "      <td>-0.005652</td>\n",
       "      <td>-0.007379</td>\n",
       "      <td>-0.001470</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>-0.003790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.023506</td>\n",
       "      <td>0.011090</td>\n",
       "      <td>-0.003510</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>0.056934</td>\n",
       "      <td>0.098202</td>\n",
       "      <td>0.130510</td>\n",
       "      <td>0.160280</td>\n",
       "      <td>0.180060</td>\n",
       "      <td>0.21011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>-0.001703</td>\n",
       "      <td>-0.001424</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>-0.006904</td>\n",
       "      <td>-0.006104</td>\n",
       "      <td>-0.001440</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>-0.004034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>-0.011548</td>\n",
       "      <td>0.025305</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.036875</td>\n",
       "      <td>0.049536</td>\n",
       "      <td>0.066969</td>\n",
       "      <td>0.083730</td>\n",
       "      <td>0.103420</td>\n",
       "      <td>0.125480</td>\n",
       "      <td>0.16158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002378</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>-0.004021</td>\n",
       "      <td>-0.001477</td>\n",
       "      <td>-0.000846</td>\n",
       "      <td>-0.001404</td>\n",
       "      <td>-0.001987</td>\n",
       "      <td>-0.002977</td>\n",
       "      <td>-0.001452</td>\n",
       "      <td>0.001027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1996</td>\n",
       "      <td>-0.036853</td>\n",
       "      <td>-0.048127</td>\n",
       "      <td>-0.021727</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>0.020413</td>\n",
       "      <td>0.029443</td>\n",
       "      <td>0.030310</td>\n",
       "      <td>0.043885</td>\n",
       "      <td>0.069490</td>\n",
       "      <td>0.10237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001412</td>\n",
       "      <td>-0.002070</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>-0.000318</td>\n",
       "      <td>-0.000741</td>\n",
       "      <td>-0.001565</td>\n",
       "      <td>-0.002887</td>\n",
       "      <td>0.002378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1997</td>\n",
       "      <td>0.011274</td>\n",
       "      <td>-0.042309</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.041144</td>\n",
       "      <td>0.048578</td>\n",
       "      <td>0.051872</td>\n",
       "      <td>0.041825</td>\n",
       "      <td>0.053639</td>\n",
       "      <td>0.073084</td>\n",
       "      <td>0.10071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003319</td>\n",
       "      <td>-0.004697</td>\n",
       "      <td>-0.005705</td>\n",
       "      <td>-0.001817</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>-0.002289</td>\n",
       "      <td>-0.003073</td>\n",
       "      <td>-0.003446</td>\n",
       "      <td>-0.002566</td>\n",
       "      <td>-0.000146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1998</td>\n",
       "      <td>0.053583</td>\n",
       "      <td>0.015161</td>\n",
       "      <td>0.057363</td>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.084376</td>\n",
       "      <td>0.079812</td>\n",
       "      <td>0.066351</td>\n",
       "      <td>0.097193</td>\n",
       "      <td>0.127860</td>\n",
       "      <td>0.15697</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005805</td>\n",
       "      <td>-0.002575</td>\n",
       "      <td>-0.002744</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>-0.003122</td>\n",
       "      <td>-0.003818</td>\n",
       "      <td>-0.002937</td>\n",
       "      <td>-0.002672</td>\n",
       "      <td>0.000917</td>\n",
       "      <td>-0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1999</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>0.038422</td>\n",
       "      <td>0.061699</td>\n",
       "      <td>0.052487</td>\n",
       "      <td>0.067543</td>\n",
       "      <td>0.065156</td>\n",
       "      <td>0.084196</td>\n",
       "      <td>0.119330</td>\n",
       "      <td>0.151100</td>\n",
       "      <td>0.17690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004246</td>\n",
       "      <td>-0.002865</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>-0.000136</td>\n",
       "      <td>-0.001713</td>\n",
       "      <td>-0.002646</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.000127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       East_12  lag_east_12        13        14        15        16        17  \\\n",
       "0    -0.017703    -0.016553  0.021267  0.042634  0.082478  0.130230  0.139420   \n",
       "1    -0.001151    -0.028014  0.027178  0.053463  0.090675  0.120980  0.137650   \n",
       "2     0.026863     0.010981  0.039995  0.089400  0.115810  0.121480  0.137530   \n",
       "3     0.015882     0.039388  0.027085  0.082073  0.115360  0.133080  0.152590   \n",
       "4    -0.023506     0.011090 -0.003510  0.034058  0.056934  0.098202  0.130510   \n",
       "...        ...          ...       ...       ...       ...       ...       ...   \n",
       "1995 -0.011548     0.025305  0.019385  0.036875  0.049536  0.066969  0.083730   \n",
       "1996 -0.036853    -0.048127 -0.021727  0.008923  0.020413  0.029443  0.030310   \n",
       "1997  0.011274    -0.042309  0.009199  0.041144  0.048578  0.051872  0.041825   \n",
       "1998  0.053583     0.015161  0.057363  0.069681  0.084376  0.079812  0.066351   \n",
       "1999  0.038422     0.038422  0.061699  0.052487  0.067543  0.065156  0.084196   \n",
       "\n",
       "            18        19       20  ...      49.2      50.2      51.2  \\\n",
       "0     0.141490  0.124130  0.14460  ...  0.002730  0.001201 -0.001766   \n",
       "1     0.148710  0.132350  0.13501  ...  0.002280 -0.000927 -0.002955   \n",
       "2     0.156670  0.142270  0.13988  ...  0.001380  0.000830 -0.001670   \n",
       "3     0.178490  0.173680  0.18923  ... -0.000976  0.001851 -0.000283   \n",
       "4     0.160280  0.180060  0.21011  ... -0.000047  0.000326 -0.001703   \n",
       "...        ...       ...      ...  ...       ...       ...       ...   \n",
       "1995  0.103420  0.125480  0.16158  ... -0.002378 -0.001360 -0.004021   \n",
       "1996  0.043885  0.069490  0.10237  ... -0.001412 -0.002070 -0.005016   \n",
       "1997  0.053639  0.073084  0.10071  ... -0.003319 -0.004697 -0.005705   \n",
       "1998  0.097193  0.127860  0.15697  ... -0.005805 -0.002575 -0.002744   \n",
       "1999  0.119330  0.151100  0.17690  ... -0.004246 -0.002865 -0.002426   \n",
       "\n",
       "          52.2      53.2      54.2      55.2      56.2      57.2      58.2  \n",
       "0     0.005172  0.004519  0.006129  0.004212  0.004655  0.001408  0.003451  \n",
       "1     0.004738  0.002229  0.001678 -0.002080  0.002313 -0.000923  0.004295  \n",
       "2     0.001650 -0.000317 -0.003118 -0.006825 -0.001222 -0.003579 -0.002215  \n",
       "3    -0.001392 -0.001417 -0.005652 -0.007379 -0.001470 -0.001904 -0.003790  \n",
       "4    -0.001424 -0.002720 -0.006904 -0.006104 -0.001440 -0.001904 -0.004034  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1995 -0.001477 -0.000846 -0.001404 -0.001987 -0.002977 -0.001452  0.001027  \n",
       "1996 -0.001092  0.000303 -0.000318 -0.000741 -0.001565 -0.002887  0.002378  \n",
       "1997 -0.001817 -0.002971 -0.002289 -0.003073 -0.003446 -0.002566 -0.000146  \n",
       "1998 -0.001202 -0.003122 -0.003818 -0.002937 -0.002672  0.000917 -0.000873  \n",
       "1999 -0.000136 -0.001713 -0.002646  0.000021 -0.001383  0.001923  0.000127  \n",
       "\n",
       "[2000 rows x 140 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_values = data.values\n",
    "features = data_values[:,1:]\n",
    "values = data_values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0165525 ,  0.021267  ,  0.042634  ,  0.082478  ,  0.13023   ,\n",
       "        0.13942   ,  0.14149   ,  0.12413   ,  0.1446    ,  0.14609   ,\n",
       "        0.15797   ,  0.15817   ,  0.18298   ,  0.20063   ,  0.19354   ,\n",
       "        0.17362   ,  0.14189   ,  0.12908   ,  0.099288  ,  0.087275  ,\n",
       "        0.094222  ,  0.075285  ,  0.092737  ,  0.099984  ,  0.097626  ,\n",
       "        0.10753   ,  0.138     ,  0.15982   ,  0.19522   ,  0.22058   ,\n",
       "        0.19663   ,  0.19659   ,  0.19191   ,  0.22582   ,  0.22947   ,\n",
       "        0.24498   ,  0.25199   ,  0.26311   ,  0.22778   ,  0.21771   ,\n",
       "        0.21851   ,  0.22598   ,  0.20083   ,  0.23436   ,  0.27743   ,\n",
       "        0.35043   ,  0.39029   ,  0.07903   ,  0.12183   ,  0.16657   ,\n",
       "        0.20121   ,  0.27049   ,  0.33337   ,  0.3659    ,  0.37105   ,\n",
       "        0.35508   ,  0.33496   ,  0.34246   ,  0.33889   ,  0.33552   ,\n",
       "        0.31189   ,  0.31892   ,  0.31178   ,  0.3275    ,  0.32089   ,\n",
       "        0.32349   ,  0.34008   ,  0.34135   ,  0.34157   ,  0.33046   ,\n",
       "        0.343     ,  0.32981   ,  0.31669   ,  0.30776   ,  0.26429   ,\n",
       "        0.23641   ,  0.24226   ,  0.26924   ,  0.26163   ,  0.23542   ,\n",
       "        0.20335   ,  0.23554   ,  0.27165   ,  0.30368   ,  0.32911   ,\n",
       "        0.32437   ,  0.33092   ,  0.28987   ,  0.2944    ,  0.37346   ,\n",
       "        0.44138   ,  0.45492   ,  0.49309   ,  0.0020728 ,  0.0039587 ,\n",
       "        0.0031854 ,  0.0038183 ,  0.0018784 ,  0.0019962 ,  0.0070503 ,\n",
       "        0.010588  ,  0.013599  ,  0.01383   ,  0.012367  ,  0.011682  ,\n",
       "        0.012807  ,  0.013811  ,  0.010086  ,  0.010652  ,  0.011807  ,\n",
       "        0.0133    ,  0.011053  ,  0.012466  ,  0.010056  ,  0.015376  ,\n",
       "        0.006214  ,  0.0045338 ,  0.0035225 ,  0.0083874 ,  0.0088258 ,\n",
       "        0.0073671 ,  0.0058671 ,  0.0029009 ,  0.0013671 ,  0.0018221 ,\n",
       "        0.0039512 ,  0.00074175,  0.0066944 ,  0.00553   ,  0.0027305 ,\n",
       "        0.0012005 , -0.0017658 ,  0.0051719 ,  0.0045188 ,  0.0061291 ,\n",
       "        0.0042117 ,  0.0046554 ,  0.0014084 ,  0.0034512 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "clf = GradientBoostingRegressor(loss='ls', learning_rate=0.1, n_estimators=100,\n",
    "       subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1,\n",
    "       min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "       init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, \n",
    "       warm_start=False, presort='auto', validation_fraction=0.1, tol=0.0001)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "clf2 = RandomForestRegressor(n_estimators=100, criterion='mse', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = []\n",
    "pred2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1599\n",
    "i = 0\n",
    "for j in range(n, len(features)-1):\n",
    "    temp_training_features = features[i:j]\n",
    "    temp_training_values = values[i:j]\n",
    "    temp_training_features.reshape(-1,1)\n",
    "    temp_training_values.reshape(-1,1)\n",
    "    clf.fit(temp_training_features, temp_training_values, sample_weight=None)\n",
    "    #clf2.fit(temp_training_features, temp_training_values, sample_weight=None)\n",
    "    # m = 1\n",
    "    test_features = features[j+1]\n",
    "    test_features.reshape(-1,1)\n",
    "    temp_pred1 = clf.predict([test_features])\n",
    "    #temp_pred2 = clf2.predict([test_features])\n",
    "    # n = n+1\n",
    "    i = i+1\n",
    "    pred1.append(temp_pred1)\n",
    "    #pred2.append(temp_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.01485082]),\n",
       " array([-0.011868]),\n",
       " array([-0.01044712]),\n",
       " array([-0.0120276]),\n",
       " array([-0.02262809]),\n",
       " array([-0.03107958]),\n",
       " array([-0.00503877]),\n",
       " array([0.04491879]),\n",
       " array([0.06306484]),\n",
       " array([0.03006844]),\n",
       " array([0.03779413]),\n",
       " array([0.07724908]),\n",
       " array([0.0914923]),\n",
       " array([0.09293347]),\n",
       " array([0.11799318]),\n",
       " array([0.1125447]),\n",
       " array([0.09522085]),\n",
       " array([0.11274471]),\n",
       " array([0.10614743]),\n",
       " array([0.0750955]),\n",
       " array([0.04935339]),\n",
       " array([0.03637043]),\n",
       " array([0.06468914]),\n",
       " array([0.09026751]),\n",
       " array([0.08909432]),\n",
       " array([0.06906955]),\n",
       " array([0.06938496]),\n",
       " array([0.06569884]),\n",
       " array([0.04549802]),\n",
       " array([0.06075688]),\n",
       " array([0.09419334]),\n",
       " array([0.11270036]),\n",
       " array([0.09508987]),\n",
       " array([0.06690479]),\n",
       " array([0.0652142]),\n",
       " array([0.07580206]),\n",
       " array([0.09508764]),\n",
       " array([0.09085449]),\n",
       " array([0.07511533]),\n",
       " array([0.08289596]),\n",
       " array([0.0994437]),\n",
       " array([0.12344359]),\n",
       " array([0.04172073]),\n",
       " array([-0.06653248]),\n",
       " array([-0.05618195]),\n",
       " array([0.01922244]),\n",
       " array([0.04004273]),\n",
       " array([0.06358065]),\n",
       " array([0.06234797]),\n",
       " array([0.04256086]),\n",
       " array([0.0673113]),\n",
       " array([0.07227607]),\n",
       " array([0.07065831]),\n",
       " array([0.10433589]),\n",
       " array([0.10822155]),\n",
       " array([0.06576393]),\n",
       " array([0.04396343]),\n",
       " array([0.08653773]),\n",
       " array([0.10595693]),\n",
       " array([0.11039587]),\n",
       " array([0.13308347]),\n",
       " array([0.16617538]),\n",
       " array([0.15971717]),\n",
       " array([0.15973485]),\n",
       " array([0.13761963]),\n",
       " array([0.13402134]),\n",
       " array([0.1226733]),\n",
       " array([0.11678453]),\n",
       " array([0.05377011]),\n",
       " array([0.05452804]),\n",
       " array([0.08357971]),\n",
       " array([0.1088754]),\n",
       " array([0.10653446]),\n",
       " array([0.10749111]),\n",
       " array([0.14174342]),\n",
       " array([0.17346419]),\n",
       " array([0.1812064]),\n",
       " array([0.18421974]),\n",
       " array([0.23923849]),\n",
       " array([0.29543069]),\n",
       " array([0.2740741]),\n",
       " array([0.27497971]),\n",
       " array([0.32439521]),\n",
       " array([0.31590397]),\n",
       " array([0.31761911]),\n",
       " array([0.29137957]),\n",
       " array([0.28322314]),\n",
       " array([0.28858906]),\n",
       " array([0.31943431]),\n",
       " array([0.2864315]),\n",
       " array([0.30757658]),\n",
       " array([0.35157028]),\n",
       " array([0.37689804]),\n",
       " array([0.31237734]),\n",
       " array([0.30526363]),\n",
       " array([0.34620738]),\n",
       " array([0.36834809]),\n",
       " array([0.39447832]),\n",
       " array([0.41681722]),\n",
       " array([0.417507]),\n",
       " array([0.39681861]),\n",
       " array([0.27876181]),\n",
       " array([0.23649241]),\n",
       " array([0.28060346]),\n",
       " array([0.41547224]),\n",
       " array([0.40237174]),\n",
       " array([0.31702463]),\n",
       " array([0.31338969]),\n",
       " array([0.32469567]),\n",
       " array([0.36227711]),\n",
       " array([0.39895659]),\n",
       " array([0.36334593]),\n",
       " array([0.32760787]),\n",
       " array([0.33499794]),\n",
       " array([0.33810961]),\n",
       " array([0.35607331]),\n",
       " array([0.39151223]),\n",
       " array([0.38242843]),\n",
       " array([0.36260768]),\n",
       " array([0.35727076]),\n",
       " array([0.32193877]),\n",
       " array([0.35921564]),\n",
       " array([0.33097565]),\n",
       " array([0.31374527]),\n",
       " array([0.32524574]),\n",
       " array([0.32401142]),\n",
       " array([0.31600513]),\n",
       " array([0.30690207]),\n",
       " array([0.34567175]),\n",
       " array([0.37103679]),\n",
       " array([0.36193384]),\n",
       " array([0.31806844]),\n",
       " array([0.30899474]),\n",
       " array([0.31346458]),\n",
       " array([0.37466167]),\n",
       " array([0.35279595]),\n",
       " array([0.3087827]),\n",
       " array([0.2594622]),\n",
       " array([0.25922182]),\n",
       " array([0.24033304]),\n",
       " array([0.22172714]),\n",
       " array([0.23623071]),\n",
       " array([0.26601012]),\n",
       " array([0.26097398]),\n",
       " array([0.24268696]),\n",
       " array([0.23079849]),\n",
       " array([0.20487214]),\n",
       " array([0.20054256]),\n",
       " array([0.19387284]),\n",
       " array([0.15182763]),\n",
       " array([0.16916972]),\n",
       " array([0.22154289]),\n",
       " array([0.22945491]),\n",
       " array([0.19924063]),\n",
       " array([0.19743434]),\n",
       " array([0.2641277]),\n",
       " array([0.26272196]),\n",
       " array([0.19850206]),\n",
       " array([0.23629273]),\n",
       " array([0.26874419]),\n",
       " array([0.25044197]),\n",
       " array([0.20344983]),\n",
       " array([0.25827412]),\n",
       " array([0.31539938]),\n",
       " array([0.30353675]),\n",
       " array([0.26623028]),\n",
       " array([0.23673926]),\n",
       " array([0.18691382]),\n",
       " array([0.23513012]),\n",
       " array([0.31928795]),\n",
       " array([0.31582533]),\n",
       " array([0.30988808]),\n",
       " array([0.28463595]),\n",
       " array([0.23917566]),\n",
       " array([0.24808275]),\n",
       " array([0.25730863]),\n",
       " array([0.29458898]),\n",
       " array([0.31459221]),\n",
       " array([0.31436038]),\n",
       " array([0.30611075]),\n",
       " array([0.26676381]),\n",
       " array([0.2609864]),\n",
       " array([0.25457673]),\n",
       " array([0.27888575]),\n",
       " array([0.26030362]),\n",
       " array([0.25399276]),\n",
       " array([0.25121197]),\n",
       " array([0.25585918]),\n",
       " array([0.23475625]),\n",
       " array([0.17476846]),\n",
       " array([0.12692877]),\n",
       " array([0.12857119]),\n",
       " array([0.19329092]),\n",
       " array([0.20390556]),\n",
       " array([0.17750409]),\n",
       " array([0.1907324]),\n",
       " array([0.22149621]),\n",
       " array([0.23615792]),\n",
       " array([0.21743662]),\n",
       " array([0.20037219]),\n",
       " array([0.19108733]),\n",
       " array([0.17394377]),\n",
       " array([0.16600549]),\n",
       " array([0.18903335]),\n",
       " array([0.23927383]),\n",
       " array([0.23831436]),\n",
       " array([0.17626914]),\n",
       " array([0.14635609]),\n",
       " array([0.1478775]),\n",
       " array([0.17016344]),\n",
       " array([0.19635943]),\n",
       " array([0.19349743]),\n",
       " array([0.17837913]),\n",
       " array([0.18329703]),\n",
       " array([0.17133482]),\n",
       " array([0.14432014]),\n",
       " array([0.17584306]),\n",
       " array([0.19162794]),\n",
       " array([0.15382626]),\n",
       " array([0.10294165]),\n",
       " array([0.08013186]),\n",
       " array([0.05917516]),\n",
       " array([0.05392998]),\n",
       " array([0.09945501]),\n",
       " array([0.13008952]),\n",
       " array([0.10184091]),\n",
       " array([0.07764517]),\n",
       " array([0.07997913]),\n",
       " array([0.07287414]),\n",
       " array([0.06780845]),\n",
       " array([0.0668941]),\n",
       " array([0.05113314]),\n",
       " array([0.02797255]),\n",
       " array([0.01086556]),\n",
       " array([0.01091363]),\n",
       " array([0.02097123]),\n",
       " array([0.03877044]),\n",
       " array([0.03784896]),\n",
       " array([0.02870023]),\n",
       " array([0.03371943]),\n",
       " array([0.03635144]),\n",
       " array([0.04723068]),\n",
       " array([0.05245785]),\n",
       " array([0.02496019]),\n",
       " array([0.00822272]),\n",
       " array([0.03468513]),\n",
       " array([0.00877407]),\n",
       " array([-0.02813145]),\n",
       " array([-0.00494268]),\n",
       " array([0.03711817]),\n",
       " array([0.04021897])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = values[1600:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9810562767301239"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(test_values, pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r2_score(test_values, pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0.9858030592317613#1\n",
    "#0.9857613191494161#2\n",
    "#0.9853963491546662#3\n",
    "#0.9853407753411109#4\n",
    "#0.9854888222455#5\n",
    "#0.9854890415802979#8\n",
    "#0.9842227305866622#24\n",
    "#0.9815789240020949#100\n",
    "#0.9812406718954232#150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
